{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86954f80-d037-4df7-b932-b77a5da00553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook mode\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    __IPYTHON__\n",
    "    is_notebook = True\n",
    "    print('Notebook mode')\n",
    "except NameError:\n",
    "    is_notebook = False\n",
    "    print('Script mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78efada-76f9-4d68-be75-3ebb73036217",
   "metadata": {},
   "source": [
    "# Pip Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fbf8ce-0447-4cf0-973e-e3d590429cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.26.74)\n",
      "Requirement already satisfied: astropy in /opt/conda/lib/python3.10/site-packages (5.2.1)\n",
      "Requirement already satisfied: sfdmap in /opt/conda/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: progressbar2 in /opt/conda/lib/python3.10/site-packages (4.2.0)\n",
      "Requirement already satisfied: GPUtil in /opt/conda/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: parse in /opt/conda/lib/python3.10/site-packages (1.19.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.74 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.29.74)\n",
      "Requirement already satisfied: packaging>=19.0 in /opt/conda/lib/python3.10/site-packages (from astropy) (21.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from astropy) (1.23.5)\n",
      "Requirement already satisfied: pyerfa>=2.0 in /opt/conda/lib/python3.10/site-packages (from astropy) (2.0.0.1)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /opt/conda/lib/python3.10/site-packages (from astropy) (6.0)\n",
      "Requirement already satisfied: python-utils>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from progressbar2) (3.5.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.74->boto3) (1.26.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.74->boto3) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=19.0->astropy) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.74->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "if is_notebook:\n",
    "    !pip install boto3 astropy sfdmap progressbar2 GPUtil parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c7e62-0177-4b1d-8359-28926b46695f",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d54be1-b1ff-45cd-8983-6ab5f0e9ad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 20:22:06.832040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 20:22:06.960392: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-18 20:22:07.565287: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-18 20:22:07.565362: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-18 20:22:07.565370: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import boto3\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# local files paths\n",
    "local_home_dir_path = os.path.expanduser(\"~\")\n",
    "local_work_dir_path = os.path.join(local_home_dir_path, 'thesis2')\n",
    "local_code_dir_path = os.path.join(local_work_dir_path , 'code')\n",
    "\n",
    "# S3 file paths\n",
    "endpoint_url = 'https://s3-west.nrp-nautilus.io'\n",
    "bucket_name = 'tau-astro'\n",
    "prefix = 'almogh'\n",
    "s3_work_dir_path = os.path.join(prefix, 'thesis2')\n",
    "s3_data_dir_path = os.path.join(s3_work_dir_path , 'data')\n",
    "s3_models_dir_path = os.path.join(s3_work_dir_path , 'models')\n",
    "s3_final_table_csv_path = os.path.join(s3_data_dir_path, 'SDSS_DR16_all.csv')\n",
    "\n",
    "s3_client = boto3.client(\"s3\", endpoint_url=endpoint_url)\n",
    "\n",
    "# adding code folder to path\n",
    "sys.path.insert(1, local_code_dir_path)\n",
    "from s3 import to_s3_npy, to_s3_pkl, from_s3_npy, from_s3_pkl, to_s3_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad730d9f-6f4d-4bd9-97c2-c463d974a4cc",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b2160f-a8ea-4d5b-a58b-11a3fce075b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from uri: s3://tau-astro/almogh/thesis2/data/BigRF/train/spec.npy\n"
     ]
    }
   ],
   "source": [
    "data_path_in_bucket = 'almogh/thesis2/data/BigRF/train/spec.npy'\n",
    "X = from_s3_npy(s3_client = s3_client,\n",
    "                bucket_name = bucket_name,\n",
    "                path_in_bucket = data_path_in_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da6e618-a166-46dd-a584-4caed7cadf97",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2bcc82-ee91-4073-b4b5-8863e66b55a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from uri: s3://tau-astro/almogh/thesis2/models/BigRF/train/rf.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load BigRF\n",
    "BigRF = from_s3_pkl(s3_client = s3_client,\n",
    "                      bucket_name = bucket_name,\n",
    "                      path_in_bucket = 'almogh/thesis2/models/BigRF/train/rf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c005002-7d4e-47a6-8c53-5bae1c26c64c",
   "metadata": {},
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0f169e-fec6-4c86-8f37-e51707e4974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Applying forest to results... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Max leaf index: \n",
      "360\n",
      "  Calculating real leafs... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 437 out of 500 | elapsed:    3.7s remaining:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Calculating similarity matrix... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    3.8s finished\n"
     ]
    }
   ],
   "source": [
    "from uRF_SDSS import calcDisMat\n",
    "dist_mat = calcDisMat(BigRF, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b05271-0c1a-4494-b876-abdc8d30b7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to uri: s3://tau-astro/almogh/thesis2/eval/inference/D_BigRF.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "to_s3_npy(dist_mat,\n",
    "          s3_client = s3_client,\n",
    "          bucket_name = bucket_name,\n",
    "          path_in_bucket = 'almogh/thesis2/eval/inference/D_BigRF.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
