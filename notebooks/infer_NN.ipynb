{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86954f80-d037-4df7-b932-b77a5da00553",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    __IPYTHON__\n",
    "    is_notebook = True\n",
    "    print('Notebook mode')\n",
    "except NameError:\n",
    "    is_notebook = False\n",
    "    print('Script mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97e0e7-6796-4385-aa0e-8aa7d444e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook:\n",
    "    i_slice = 0\n",
    "    n_slices = 16\n",
    "else:\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"i_slice\", help=\"slice index\", type=int)\n",
    "    parser.add_argument(\"n_slices\", help=\"number of slices\", type=int)\n",
    "    args = parser.parse_args()\n",
    "    print('args:\\n\\t'+'\\n\\t'.join(f'{k} = {v}' for k, v in vars(args).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78efada-76f9-4d68-be75-3ebb73036217",
   "metadata": {},
   "source": [
    "# Pip Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbf8ce-0447-4cf0-973e-e3d590429cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook:\n",
    "    !pip install boto3 astropy sfdmap progressbar2 GPUtil parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c7e62-0177-4b1d-8359-28926b46695f",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158bd42-fd1a-48d0-bc28-d76a9570ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "print('GPUs:\\n{0}'.format('\\n'.join(['('+str(i+1)+')\\t'+gpu.name+'\\t-\\t{:.2f}GB'.format(gpu.memoryFree/1e3) for i,gpu in enumerate(GPUtil.getGPUs())])))\n",
    "N_GPUs = len(GPUtil.getGPUs())\n",
    "\n",
    "# setting environ variables using !\n",
    "if is_notebook:\n",
    "    !export TF_GPU_THREAD_MODE=\"gpu_private\"\n",
    "    if N_GPUs>1:\n",
    "        if N_GPUs==2:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=2\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1\"\n",
    "        if N_GPUs==3:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=3\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2\"\n",
    "        if N_GPUs==4:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=4\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2,3\"\n",
    "        if N_GPUs==5:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=5\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2,3,4\"\n",
    "        if N_GPUs==6:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=6\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2,3,4,5\"\n",
    "        if N_GPUs==7:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=7\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2,3,4,5,6\"\n",
    "        if N_GPUs==8:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=8\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2,3,4,5,6,7\"\n",
    "\n",
    "# set environ variables using os.environ\n",
    "import os \n",
    "if N_GPUs>1:\n",
    "    os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"]=str(N_GPUs)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=','.join([str(i) for i in range(N_GPUs)])\n",
    "os.environ[\"TF_GPU_THREAD_MODE\"]=\"gpu_private\"\n",
    "\n",
    "# make sure tensorflow detect the GPUs\n",
    "import tensorflow as tf\n",
    "assert len(tf.config.list_physical_devices('GPU'))==N_GPUs, 'Not all GPUs are available!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d54be1-b1ff-45cd-8983-6ab5f0e9ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import boto3\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# local files paths\n",
    "local_home_dir_path = os.path.expanduser(\"~\")\n",
    "local_work_dir_path = os.path.join(local_home_dir_path, 'thesis2')\n",
    "local_code_dir_path = os.path.join(local_work_dir_path , 'code')\n",
    "\n",
    "# S3 file paths\n",
    "endpoint_url = 'https://s3-west.nrp-nautilus.io'\n",
    "bucket_name = 'tau-astro'\n",
    "prefix = 'almogh'\n",
    "s3_work_dir_path = os.path.join(prefix, 'thesis2')\n",
    "s3_data_dir_path = os.path.join(s3_work_dir_path , 'data')\n",
    "s3_models_dir_path = os.path.join(s3_work_dir_path , 'models')\n",
    "s3_final_table_csv_path = os.path.join(s3_data_dir_path, 'SDSS_DR16_all.csv')\n",
    "\n",
    "s3_client = boto3.client(\"s3\", endpoint_url=endpoint_url)\n",
    "\n",
    "# adding code folder to path\n",
    "sys.path.insert(1, local_code_dir_path)\n",
    "from s3 import to_s3_npy, to_s3_pkl, from_s3_npy, from_s3_pkl, to_s3_fig\n",
    "from s3 import log_s3, s3_save_TF_model, s3_load_TF_model\n",
    "from NN import DistanceLayer, SiameseModel, DistillationDataGenerator, L1, L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072441ee-ef84-406f-b644-07af1ed34b67",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840841c-33d7-414c-aa99-95ffeeecfe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_in_bucket = 'almogh/thesis2/data/BigRF/train/spec.npy'\n",
    "X = from_s3_npy(s3_client = s3_client,\n",
    "                bucket_name = bucket_name,\n",
    "                path_in_bucket = data_path_in_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6890abf-23a4-42da-a502-125a557862d6",
   "metadata": {},
   "source": [
    "# Load the model and infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478840f-bc5a-42e9-a7f7-b19cd6ebd335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN import DistanceLayer, L1, L2, SiameseModel, DistillationDataGenerator, full_dist_mat_from_upper_diag_part\n",
    "from s3 import s3_download_model\n",
    "import tempfile\n",
    "from tensorflow.keras import optimizers, mixed_precision\n",
    "\n",
    "custom_objects = {'DistanceLayer': DistanceLayer, 'L1':L1, 'L2':L2, 'SiameseModel':SiameseModel}\n",
    "batch_size = 128*N_GPUs\n",
    "verbosity = 1 if is_notebook else 2\n",
    "\n",
    "if N_GPUs>1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    # load model from S3\n",
    "    model_name = 'model'\n",
    "    with tempfile.TemporaryDirectory() as tempdir:\n",
    "        s3_download_model(s3_client = s3_client,\n",
    "                          bucket_name = bucket_name,\n",
    "                          path_in_bucket = 'almogh/thesis2/models/NN/train/after_50_epochs/model',\n",
    "                          model_name = model_name,\n",
    "                          tempdir = tempdir)\n",
    "        NN = tf.keras.models.load_model(f\"{tempdir}/{model_name}\", custom_objects=custom_objects)\n",
    "        \n",
    "    # compile the model\n",
    "    optimizer = optimizers.Adam(0.001)\n",
    "    optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "\n",
    "    NN.compile(optimizer=optimizer)\n",
    "    \n",
    "    # predict\n",
    "    \n",
    "    data_gen = DistillationDataGenerator(X, np.zeros(shape=(X.shape[0], X.shape[0])), batch_size=batch_size, shuffle=False, seed=42, full_epoch=True, norm=True, i_slice=i_slice, n_slices=n_slices)\n",
    "    Z_NN = NN.predict(data_gen, verbose=verbosity, workers=2*N_GPUs, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a5dac4-acad-488d-88f7-7b8ce7fc871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "to_s3_npy(dist_mat,\n",
    "          s3_client = s3_client,\n",
    "          bucket_name = bucket_name,\n",
    "          path_in_bucket = 'almogh/thesis2/eval/inference/Z_NN_i{0}_n{1}.npy'.format(i_slice, n_slices))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
