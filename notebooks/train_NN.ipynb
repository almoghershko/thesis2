{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e01fc00-bb08-4ad3-9476-f1eae1796bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    __IPYTHON__\n",
    "    is_notebook = True\n",
    "    print('Notebook mode')\n",
    "except NameError:\n",
    "    is_notebook = False\n",
    "    print('Script mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f91721-e7de-42ec-9105-b5aad92ad538",
   "metadata": {},
   "outputs": [],
   "source": [
    "IsSmallDataSlice = True\n",
    "IsShortEpochs = False\n",
    "IsShortTraining = True\n",
    "IsSaveModel = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4740f-539c-4270-80d1-5af8c556fbfc",
   "metadata": {},
   "source": [
    "# Pip Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce95ab-77e2-4003-909b-1b5236111549",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook:\n",
    "    !pip install boto3 astropy sfdmap progressbar2 GPUtil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fff225-e870-4b7f-95b0-220564a5e5c0",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713f36ea-30ba-46fe-8d03-0af1def3827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "print('GPUs:\\n{0}'.format('\\n'.join(['('+str(i+1)+')\\t'+gpu.name for i,gpu in enumerate(GPUtil.getGPUs())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae34e55-852b-4742-a159-5091ccfe6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GPUs = len(GPUtil.getGPUs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1126d-04c1-4bf0-a077-f55b74d1f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = GPUtil.getGPUs()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1fd897-33dd-4e92-a32b-113d7adaa346",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu.memoryFree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09b910-34cc-41ae-9564-67e9735e56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook:\n",
    "    !export TF_GPU_THREAD_MODE=\"gpu_private\"\n",
    "    if N_GPUs>1:\n",
    "        if N_GPUs==2:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=2\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1\"\n",
    "        if N_GPUs==3:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=3\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2\"\n",
    "        if N_GPUs==4:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=4\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2,3\"\n",
    "        if N_GPUs==5:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=5\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2,3,4\"\n",
    "        if N_GPUs==6:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=6\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2,3,4,5\"\n",
    "        if N_GPUs==7:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=7\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2,3,4,5,6\"\n",
    "        if N_GPUs==8:\n",
    "            !export TF_MIN_GPU_MULTIPROCESSOR_COUNT=8\n",
    "            !export CUDA_VISIBLE_DEVICES=\"0,1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62adc53d-40f3-405f-9dc1-1233ce6feab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "if N_GPUs>1:\n",
    "    os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"]=str(N_GPUs)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=','.join([str(i) for i in range(N_GPUs)])\n",
    "os.environ[\"TF_GPU_THREAD_MODE\"]=\"gpu_private\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be4039-d67e-4613-bb6b-14bcf9fc9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "assert len(tf.config.list_physical_devices('GPU'))==N_GPUs, 'Not all GPUs are available!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7eada4-1aa9-420a-aa90-fbdcb0ccce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b7d43-37fd-47d9-92db-576b39e6c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import boto3\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# local files paths\n",
    "local_home_dir_path = os.path.expanduser(\"~\")\n",
    "local_work_dir_path = os.path.join(local_home_dir_path, 'thesis2')\n",
    "local_code_dir_path = os.path.join(local_work_dir_path , 'code')\n",
    "\n",
    "# S3 file paths\n",
    "endpoint_url = 'https://s3-west.nrp-nautilus.io'\n",
    "bucket_name = 'tau-astro'\n",
    "prefix = 'almogh'\n",
    "s3_work_dir_path = os.path.join(prefix, 'thesis2')\n",
    "s3_data_dir_path = os.path.join(s3_work_dir_path , 'data')\n",
    "s3_models_dir_path = os.path.join(s3_work_dir_path , 'models')\n",
    "s3_final_table_csv_path = os.path.join(s3_data_dir_path, 'SDSS_DR16_all.csv')\n",
    "\n",
    "s3_client = boto3.client(\"s3\", endpoint_url=endpoint_url)\n",
    "\n",
    "# adding code folder to path\n",
    "sys.path.insert(1, local_code_dir_path)\n",
    "from s3 import to_s3_npy, to_s3_pkl, from_s3_npy, from_s3_pkl, to_s3_fig\n",
    "from s3 import log_s3, s3_save_TF_model\n",
    "from NN import DistanceLayer, SiameseModel, DistillationDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d015ad7-5b0a-4e6c-87c3-1df0efd010e1",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d480a-6c2f-4c18-80f2-e5f3026f64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_name = 'NN'\n",
    "save_model_name = 'NN3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce71579-20f9-4ffe-849b-0bb5a7369382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model paths\n",
    "s3_model_dir_path = os.path.join(s3_models_dir_path, save_model_name)\n",
    "s3_model_train_dir_path = os.path.join(s3_model_dir_path, 'train')\n",
    "s3_model_test_dir_path = os.path.join(s3_model_dir_path, 'test')\n",
    "# prepare data paths\n",
    "s3_data_model_dir_path = os.path.join(s3_data_dir_path, data_model_name)\n",
    "s3_data_train_dir_path = os.path.join(s3_data_model_dir_path, 'train')\n",
    "s3_data_val_dir_path = os.path.join(s3_data_model_dir_path, 'val')\n",
    "s3_data_test_dir_path = os.path.join(s3_data_dir_path, 'SmallRF', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01a8a1-f157-461c-83d1-2fb204d00a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dist_mat_path = os.path.join(s3_models_dir_path, 'SmallRF', 'train', 'dist_mat.npy')\n",
    "dist_mat = from_s3_npy(s3_client, bucket_name, dist_mat_path)\n",
    "X_train = from_s3_npy(s3_client, bucket_name, os.path.join(s3_data_train_dir_path, 'spec.npy'))\n",
    "X_val = from_s3_npy(s3_client, bucket_name, os.path.join(s3_data_val_dir_path, 'spec.npy'))\n",
    "X_test = from_s3_npy(s3_client, bucket_name, os.path.join(s3_data_test_dir_path, 'spec.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7eaa2-4f78-45d3-9e58-4aef8659d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_SmallRF_train = from_s3_pkl(s3_client, bucket_name, os.path.join(s3_data_dir_path, 'SmallRF', 'train', 'gs.pkl')) # <- This is equal to g_NN\n",
    "gs = from_s3_pkl(s3_client, bucket_name, os.path.join(s3_data_model_dir_path, 'gs.pkl'))\n",
    "gs_train = from_s3_pkl(s3_client, bucket_name, os.path.join(s3_data_train_dir_path, 'gs.pkl'))\n",
    "gs_val = from_s3_pkl(s3_client, bucket_name, os.path.join(s3_data_val_dir_path, 'gs.pkl'))\n",
    "gs_test = from_s3_pkl(s3_client, bucket_name, os.path.join(s3_data_test_dir_path, 'gs.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad42ab-0e73-4891-bc41-26e50411e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_train = np.array([np.where(gs.index == i)[0][0] for i in gs_train.index])\n",
    "I_val = np.array([np.where(gs.index == i)[0][0] for i in gs_val.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15dd32-7ee5-4640-b738-80135cd87c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat_train = dist_mat[I_train,:][:,I_train]\n",
    "dist_mat_val = dist_mat[I_val,:][:,I_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4281199a-32d8-4acf-979f-3c40d7d08105",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IsSmallDataSlice:\n",
    "    print('Running on a tiny slice of the data')\n",
    "    N_nb = 500\n",
    "    X_train = X_train[:N_nb,:]\n",
    "    X_val = X_val[:N_nb,:]\n",
    "    X_test = X_test[:N_nb,:]\n",
    "    dist_mat_train = dist_mat_train[:N_nb,:][:,:N_nb]\n",
    "    dist_mat_val = dist_mat_val[:N_nb,:][:,:N_nb]\n",
    "    gs_train = gs_train[:N_nb]\n",
    "    gs_val = gs_val[:N_nb]\n",
    "    gs_test = gs_test[:N_nb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4289681-93ec-48f1-8e42-e9ed69bc3c77",
   "metadata": {},
   "source": [
    "## Get SNR histogram of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e501aee-12ca-49c2-9d66-8fcfaa5ec5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_full = from_s3_pkl(s3_client, bucket_name, 'almogh/thesis2/data/BigRF/gs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597cebe9-e45d-4a0c-8d56-00a36e20efee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(gs_full.snMedian, bins=100, density=True)\n",
    "plt.xlabel('snMedian')\n",
    "plt.ylabel('Pr')\n",
    "plt.title('SNR distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abda66-24b3-4530-a3d0-1e069976f81d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snr_pool = np.array(gs_full.snMedian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068ba31-e817-4ce1-807b-a32a5b963a07",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247d25a-255e-4d50-b87e-86b3322aa377",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02f9bb-3f08-43da-849a-511a3f6f03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf27f52-4944-418c-b456-62f120096c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "from NN import DistanceLayer\n",
    "\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60991b0-352e-488a-8048-ffedc5da09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "encoding_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97253f5-1b3c-4901-9ab4-1a56ea14faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if N_GPUs>1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1bcd2-e608-4301-8a54-07228512c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    ##############################\n",
    "    #     Embedding Network      #\n",
    "    ##############################\n",
    "    \n",
    "    # input layer\n",
    "    x_in = layers.Input(shape=(N_features, 1))\n",
    "\n",
    "    # adding the network layers\n",
    "    x = x_in\n",
    "    x = layers.Conv1D(64, 31, activation=None, padding='same', kernel_initializer=initializers.GlorotUniform(seed=seed))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = activations.relu(x)\n",
    "    x = layers.AveragePooling1D( 2, padding='same')(x)\n",
    "    x = layers.Conv1D(32, 31, activation=None, padding='same', kernel_initializer=initializers.GlorotUniform(seed=seed))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = activations.relu(x)\n",
    "    x = layers.AveragePooling1D( 2, padding='same')(x)\n",
    "    x = layers.Conv1D(16, 31, activation=None, padding='same', kernel_initializer=initializers.GlorotUniform(seed=seed))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = activations.relu(x)\n",
    "    x = layers.AveragePooling1D( 2, padding='same')(x)\n",
    "    x = layers.Conv1D(8, 31, activation=None, padding='same', kernel_initializer=initializers.GlorotUniform(seed=seed))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = activations.relu(x)\n",
    "    x = layers.AveragePooling1D( 2, padding='same')(x)\n",
    "    x = layers.Conv1D(4, 31, activation=None, padding='same', kernel_initializer=initializers.GlorotUniform(seed=seed))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = activations.relu(x)\n",
    "    x = layers.AveragePooling1D( 2, padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(hidden_size, kernel_initializer=initializers.GlorotUniform(seed=seed))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = activations.relu(x)\n",
    "    x = layers.Dense(encoding_size, kernel_initializer=initializers.GlorotUniform(seed=seed))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    #x = activations.tanh(x, dtype='float32')\n",
    "    x = layers.Activation('tanh', dtype='float32', name='encoding')(x)\n",
    "    x_out = x\n",
    "\n",
    "    # creating the model\n",
    "    encoding = Model(x_in, x_out)\n",
    "    \n",
    "    ##############################\n",
    "    #     Siamese Network        #\n",
    "    ##############################\n",
    "    first_input = layers.Input(name=\"first_input\", shape=(N_features))\n",
    "    second_input = layers.Input(name=\"second_input\", shape=(N_features))\n",
    "\n",
    "    first_encoding = encoding(first_input)\n",
    "    second_encoding = encoding(second_input)\n",
    "\n",
    "    #distance = tf.sqrt(tf.maximum(tf.reduce_sum(tf.square(first_encoding - second_encoding), -1),1e-9))\n",
    "    distance = DistanceLayer(dtype=mixed_precision.Policy('float32'))(first_encoding, second_encoding)\n",
    "\n",
    "    siamese_network = Model(\n",
    "        inputs=[first_input, second_input], outputs=distance\n",
    "    )\n",
    "    \n",
    "    ##############################\n",
    "    #     Siamese Model          #\n",
    "    ##############################\n",
    "    \n",
    "    siamese_model = SiameseModel(siamese_network, dist_loss='L1')\n",
    "\n",
    "optimizer = optimizers.Adam(0.001)\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "    \n",
    "siamese_model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0566a-c249-41ab-9cdd-4ed179f2e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bff438-5ad0-4ca3-9769-3efd08b7b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e226e6c-f8ef-4089-b15b-1b3845993309",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381bd5de-c630-4e68-a1ab-80cde447e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IsShortEpochs:\n",
    "    print('Running short epochs')\n",
    "    full_epoch = False\n",
    "else:\n",
    "    print('Running full epochs')\n",
    "    full_epoch = True\n",
    "    \n",
    "batch_size = 128*N_GPUs\n",
    "\n",
    "train_gen = DistillationDataGenerator(X_train, dist_mat_train, batch_size=batch_size, shuffle=True, seed=seed, snr_pool=snr_pool, full_epoch=full_epoch, norm=True)\n",
    "val_gen = DistillationDataGenerator(X_val, dist_mat_val, batch_size=batch_size, shuffle=True, seed=seed, snr_pool=snr_pool, full_epoch=full_epoch, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44296b-845e-4790-ac86-45239198f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(fig, ax, e, loss_history, val_loss_history):\n",
    "    if ax.lines:\n",
    "        for i,line in enumerate(ax.lines):\n",
    "            line.set_xdata(e)\n",
    "            if (i==1):\n",
    "                line.set_ydata(loss_history)\n",
    "            else:\n",
    "                line.set_ydata(val_loss_history)\n",
    "    else:\n",
    "        ax.plot(e, loss_history, label='training')\n",
    "        ax.plot(e, val_loss_history, label='validation')\n",
    "        ax.legend()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b577595-26f9-4a91-a037-6bea87f8379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorBoard callback\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "profile_batch = '{0},{1}'.format(str(int(len(train_gen)/2)),str(20+int(len(train_gen)/2)))\n",
    "print('profile_batch={0}'.format(profile_batch))\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = profile_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877587d-1d92-4d79-8387-1f3a3860bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IsShortTraining:\n",
    "    epochs = 5\n",
    "    sub_epochs = 5\n",
    "else:\n",
    "    epochs = 50\n",
    "    sub_epochs = 5\n",
    "N_chunks = int(epochs/sub_epochs)\n",
    "loss_history = []\n",
    "val_loss_history = []\n",
    "verbosity = 1 if is_notebook else 2\n",
    "\n",
    "# training loop\n",
    "print('Training for {0} full epochs, and stopping for saving every {1} full epochs, for a total of {2} stages.'.format(epochs,sub_epochs, N_chunks))\n",
    "start_time = time.time()\n",
    "for i_chunk in range(N_chunks):\n",
    "    \n",
    "    print('-------------------------------------')\n",
    "    print('epochs {0}-{1}:'.format(i_chunk*sub_epochs+1, (i_chunk+1)*sub_epochs))\n",
    "    print('-------------------------------------')\n",
    "\n",
    "    # train\n",
    "    try:\n",
    "        # for some reason, the first call to fit will throw KeyError...\n",
    "        history = siamese_model.fit(train_gen, epochs=sub_epochs, validation_data=val_gen, verbose=verbosity, callbacks = [tboard_callback], workers=N_GPUs, use_multiprocessing=True)\n",
    "        #history = siamese_model.fit(train_gen, epochs=sub_epochs, validation_data=val_gen, verbose=verbosity, callbacks = [tboard_callback])\n",
    "    except KeyError:\n",
    "        history = siamese_model.fit(train_gen, epochs=sub_epochs, validation_data=val_gen, verbose=verbosity, callbacks = [tboard_callback], workers=N_GPUs, use_multiprocessing=True)\n",
    "        #history = siamese_model.fit(train_gen, epochs=sub_epochs, validation_data=val_gen, verbose=verbosity, callbacks = [tboard_callback])\n",
    "    loss_history += history.history['loss']\n",
    "    val_loss_history += history.history['val_loss']\n",
    "    \n",
    "    # create the figures for the loss\n",
    "    loss_fig, loss_ax = plt.subplots(figsize=(15,8))\n",
    "    loss_ax.set_title('Training curve')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.grid()\n",
    "    log_loss_fig, log_loss_ax = plt.subplots(figsize=(15,8))\n",
    "    log_loss_ax.set_title('Training curve (Log Scale)')\n",
    "    log_loss_ax.set_xlabel('epoch')\n",
    "    log_loss_ax.set_ylabel('log(loss)')\n",
    "    log_loss_ax.grid()\n",
    "    log_loss_ax.set_yscale('log')\n",
    "    \n",
    "    # plot the loss\n",
    "    curr_epochs = (i_chunk+1)*sub_epochs\n",
    "    e = np.arange(curr_epochs)+1\n",
    "    plot_loss(loss_fig, loss_ax, e, loss_history, val_loss_history)\n",
    "    plot_loss(log_loss_fig, log_loss_ax, e, loss_history, val_loss_history)\n",
    "    plt.show()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    time_str = 'TOTAL TIME = {0:.3f} hours'.format((end_time - start_time)/3600)\n",
    "    print(time_str)\n",
    "    \n",
    "    if IsSaveModel:\n",
    "    \n",
    "        # create a sub dir\n",
    "        s3_save_NN_dir_path_sub_epoch = os.path.join(s3_model_train_dir_path, 'after_{0}_epochs'.format((i_chunk+1)*sub_epochs))\n",
    "        # save the figures\n",
    "        to_s3_fig(loss_fig, s3_client, bucket_name, os.path.join(s3_save_NN_dir_path_sub_epoch, 'loss.png'))\n",
    "        to_s3_fig(log_loss_fig, s3_client, bucket_name, os.path.join(s3_save_NN_dir_path_sub_epoch, 'loss.png'))\n",
    "        # save the losses\n",
    "        to_s3_npy(np.array(loss_history), s3_client, bucket_name, os.path.join(s3_save_NN_dir_path_sub_epoch, 'loss.npy'))\n",
    "        to_s3_npy(np.array(val_loss_history), s3_client, bucket_name, os.path.join(s3_save_NN_dir_path_sub_epoch, 'val_loss.npy'))\n",
    "        # get model summary\n",
    "        stringlist = []\n",
    "        encoding.summary(print_fn=lambda x: stringlist.append(x))\n",
    "        encoding_summary = \"\\n\".join(stringlist)\n",
    "        stringlist = []\n",
    "        siamese_network.summary(print_fn=lambda x: stringlist.append(x))\n",
    "        siamese_network_summary = \"\\n\".join(stringlist)\n",
    "        # save log\n",
    "        log_s3(s3_client, bucket_name, s3_model_train_dir_path, 'NN_log.txt',\n",
    "            dist_mat_path = dist_mat_path,\n",
    "            s3_model_train_dir_path = s3_model_train_dir_path,\n",
    "            training_duration = time_str,\n",
    "            encoding_summary = encoding_summary,\n",
    "            siamese_network_summary = siamese_network_summary\n",
    "            )\n",
    "        # save the network\n",
    "        s3_model_path = os.path.join(s3_save_NN_dir_path_sub_epoch, 'model')\n",
    "        s3_save_TF_model(siamese_model, s3_client, bucket_name, s3_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eec060-75b6-478b-9b0a-12c228730bb2",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c1793-fe7b-4a65-a087-09bc17d7c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_dist_mat(model, X, verbosity):\n",
    "    # predict\n",
    "    data_gen = DistillationDataGenerator(X, np.zeros(shape=(X.shape[0], X.shape[0])), batch_size=128, shuffle=False, seed=seed, full_epoch=True, norm=True)\n",
    "    Z_NN = model.predict(data_gen, verbose=verbosity)\n",
    "    # create full distance matrix\n",
    "    N = int((-1+np.sqrt(1+8*len(Z_NN)))/2)\n",
    "    D_NN = np.zeros(shape=(N,N))\n",
    "    D_NN[np.triu_indices(N)] = Z_NN\n",
    "    D_NN = D_NN.T\n",
    "    D_NN[np.triu_indices(N)] = Z_NN\n",
    "    return D_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4d3bd-a97d-4074-a942-cc51d3dd7378",
   "metadata": {},
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0bcb8d-ef7f-4b88-bc72-66f21a7844d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = infer_dist_mat(siamese_model, X_train, verbosity)\n",
    "if IsSaveModel:\n",
    "    to_s3_npy(dist_mat, s3_client, bucket_name, os.path.join(s3_model_train_dir_path, 'dist_mat.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873b7b4-3560-4fe4-ac25-bee32514f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_scores = np.mean(dist_mat, axis=1)\n",
    "if IsSaveModel:\n",
    "    to_s3_npy(weird_scores, s3_client, bucket_name, os.path.join(s3_model_train_dir_path, 'weird_scores.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9911fdd9-b312-44a2-a967-3a130d1e0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "sne = TSNE(n_components=2, perplexity=25, metric='precomputed', verbose=1, random_state=seed, init='random').fit_transform(dist_mat)\n",
    "if IsSaveModel:\n",
    "    to_s3_npy(sne, s3_client, bucket_name, os.path.join(s3_model_train_dir_path, 'tsne.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df8f35-9f1b-4f21-93be-fcf5625e2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "tmp = plt.hist(weird_scores, bins=60, color=\"g\")\n",
    "plt.title(\"Weirdness score histogram\")\n",
    "plt.ylabel(\"N\")\n",
    "plt.xlabel(\"weirdness score\")\n",
    "if IsSaveModel:\n",
    "    to_s3_fig(fig, s3_client, bucket_name, os.path.join(s3_model_train_dir_path, 'weirdness_scores_histogram.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6aad7-cf5e-4fb7-80a8-a9ffcb2ed6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = dist_mat[np.tril_indices(dist_mat.shape[0], -1)]\n",
    "\n",
    "fig = plt.figure()\n",
    "tmp = plt.hist(distances, bins=100)\n",
    "plt.title(\"Distances histogram\")\n",
    "plt.ylabel(\"N\")\n",
    "plt.xlabel(\"distance\")\n",
    "\n",
    "if IsSaveModel:\n",
    "    to_s3_fig(fig, s3_client, bucket_name, os.path.join(s3_model_train_dir_path, 'distances_histogram.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c712428-cb37-44ec-b2ae-67130c4867cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sne_f1 = sne[:, 0]\n",
    "sne_f2 = sne[:, 1]\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111)\n",
    "im_scat = ax.scatter(sne_f1, sne_f2, s=3, c=weird_scores, cmap=plt.cm.get_cmap('jet'), picker=1)\n",
    "ax.set_xlabel('t-SNE Feature 1')\n",
    "ax.set_ylabel('t-SNE Feature 2')\n",
    "ax.set_title(r't-SNE Scatter Plot Colored by Weirdness score')\n",
    "clb = fig.colorbar(im_scat, ax=ax)\n",
    "clb.ax.set_ylabel('Weirdness', rotation=270)\n",
    "plt.show()\n",
    "\n",
    "if IsSaveModel:\n",
    "    to_s3_fig(fig, s3_client, bucket_name, os.path.join(s3_model_train_dir_path, 'tsne_colored_by_weirdness.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77861c24-059b-41ef-890c-afd4c416ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = gs_train.snMedian\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111)\n",
    "import matplotlib.colors as colors\n",
    "im_scat = ax.scatter(sne_f1, sne_f2, s=3, c=snr, cmap=plt.cm.get_cmap('jet'), norm=colors.LogNorm(vmin=snr.min(), vmax=80))\n",
    "ax.set_xlabel('t-SNE Feature 1')\n",
    "ax.set_ylabel('t-SNE Feature 2')\n",
    "ax.set_title(r't-SNE Scatter Plot Colored by SNR')\n",
    "clb = fig.colorbar(im_scat, ax=ax)\n",
    "clb.ax.set_ylabel('SNR', rotation=270)\n",
    "plt.show()\n",
    "\n",
    "if IsSaveModel:\n",
    "    to_s3_fig(fig, s3_client, bucket_name, os.path.join(s3_model_train_dir_path, 'tsne_colored_by_snr.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d40ce-b145-4105-938e-c81cd32328ed",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372d09a-11a4-4084-9216-ba8469c0aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat_test = infer_dist_mat(siamese_model, X_test, verbosity)\n",
    "if IsSaveModel:\n",
    "    to_s3_npy(dist_mat_test, s3_client, bucket_name, os.path.join(s3_model_test_dir_path, 'dist_mat.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eea1ab-90c9-47b3-bcf7-5ffb4b69b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_scores_test = np.mean(dist_mat_test, axis=1)\n",
    "if IsSaveModel:\n",
    "    to_s3_npy(weird_scores_test, s3_client, bucket_name, os.path.join(s3_model_test_dir_path, 'weird_scores.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc5823-f0d2-4917-8263-09d55c076495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "sne_test = TSNE(n_components=2, perplexity=25, metric='precomputed', verbose=1, random_state=seed, init='random').fit_transform(dist_mat_test)\n",
    "if IsSaveModel:\n",
    "    to_s3_npy(sne_test, s3_client, bucket_name, os.path.join(s3_model_test_dir_path, 'tsne.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e52d4-0b45-4ea6-8061-b82ca2f24058",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "tmp = plt.hist(weird_scores_test, bins=60, color=\"g\")\n",
    "plt.title(\"Weirdness score histogram\")\n",
    "plt.ylabel(\"N\")\n",
    "plt.xlabel(\"weirdness score\")\n",
    "if IsSaveModel:\n",
    "    to_s3_fig(fig, s3_client, bucket_name, os.path.join(s3_model_test_dir_path, 'weirdness_scores_histogram.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56492464-c3b6-4540-af9f-c91276926da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_test = dist_mat_test[np.tril_indices(dist_mat_test.shape[0], -1)]\n",
    "\n",
    "fig = plt.figure()\n",
    "tmp = plt.hist(distances_test, bins=100)\n",
    "plt.title(\"Distances histogram\")\n",
    "plt.ylabel(\"N\")\n",
    "plt.xlabel(\"distance\")\n",
    "\n",
    "if IsSaveModel:\n",
    "    to_s3_fig(fig, s3_client, bucket_name, os.path.join(s3_model_test_dir_path, 'distances_histogram.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc93f89-9987-44f9-9c85-969d966a33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sne_f1_test = sne_test[:, 0]\n",
    "sne_f2_test = sne_test[:, 1]\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111)\n",
    "im_scat = ax.scatter(sne_f1_test, sne_f2_test, s=3, c=weird_scores_test, cmap=plt.cm.get_cmap('jet'), picker=1)\n",
    "ax.set_xlabel('t-SNE Feature 1')\n",
    "ax.set_ylabel('t-SNE Feature 2')\n",
    "ax.set_title(r't-SNE Scatter Plot Colored by Weirdness score')\n",
    "clb = fig.colorbar(im_scat, ax=ax)\n",
    "clb.ax.set_ylabel('Weirdness', rotation=270)\n",
    "plt.show()\n",
    "\n",
    "if IsSaveModel:\n",
    "    to_s3_fig(fig, s3_client, bucket_name, os.path.join(s3_model_test_dir_path, 'tsne_colored_by_weirdness.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69052a30-d450-47dd-9644-e6634dd0f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_test = gs_test.snMedian\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111)\n",
    "import matplotlib.colors as colors\n",
    "im_scat = ax.scatter(sne_f1_test, sne_f2_test, s=3, c=snr_test, cmap=plt.cm.get_cmap('jet'), norm=colors.LogNorm(vmin=snr.min(), vmax=80))\n",
    "ax.set_xlabel('t-SNE Feature 1')\n",
    "ax.set_ylabel('t-SNE Feature 2')\n",
    "ax.set_title(r't-SNE Scatter Plot Colored by SNR')\n",
    "clb = fig.colorbar(im_scat, ax=ax)\n",
    "clb.ax.set_ylabel('SNR', rotation=270)\n",
    "plt.show()\n",
    "\n",
    "if IsSaveModel:\n",
    "    to_s3_fig(fig, s3_client, bucket_name, os.path.join(s3_model_test_dir_path, 'tsne_colored_by_snr.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
